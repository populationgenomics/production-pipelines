"""
take the data which has already been annotated, and run Talos on it
"""

from cpg_utils import to_path, hail_batch

pedigree = 'gs://cpg-acute-care-test/talos_benchmarking/singleton.ped'
phenopackets = 'gs://cpg-acute-care-test/talos_benchmarking/phenopackets.ped'

batch_instance = hail_batch.get_batch('Run Talos with Nextflow')

# read the pedigree and phenopackets
local_ped = batch_instance.read_input(pedigree)
local_pp = batch_instance.read_input(phenopackets)

# read in some annotations
local_hpo = batch_instance.read_input('gs://cpg-common-test/references/aip/hpo_terms.obo')
local_phenio = batch_instance.read_input('gs://cpg-common-test/references/aip/phenotype.db')
local_g2p = batch_instance.read_input('gs://cpg-common-test/references/aip/genes_to_phenotype.txt')
local_mane = batch_instance.read_input('gs://cpg-common-main/references/mane_1.4/mane_1.4.json')

# clinvarbitration data
local_clinvar = batch_instance.read_input('gs://cpg-acute-care-test/talos_benchmarking/clinvarbitration.tar.gz')

# the config file generated in main
local_conf = batch_instance.read_input('gs://cpg-acute-care-test/talos_benchmarking/runtime_conf.toml')

local_panelapp = batch_instance.read_input('gs://cpg-acute-care-test/talos_benchmarking/panelapp.json')

# the image to use
image = 'australia-southeast1-docker.pkg.dev/cpg-common/images-dev/talos:PR_552'

# the two types of input directories
# this was generated by merging the single samples VCFs
ss_annotated_dir = 'gs://cpg-acute-care-test/talos_benchmarking/ms_merged_results'
# this was multisample VCFs exported straight from a MatrixTable as a multisample VCF
ms_annotated_dir = 'gs://cpg-acute-care-test/talos_benchmarking/ms_results_trimmed'

output_prefix = 'gs://cpg-acute-care-test/talos_benchmarking/talos_results_singletons'

for each_group in [5, 10, 25, 50, 100, 250]:

    for run_type, input_dir, output_name in [
        ('nf_merged', 'ms_merged_results', 'solo_vcfs_merged'),
        ('joint_called', 'ms_results_trimmed', 'joint_call_from_hail')
    ]:

        # create this input directory
        input_dir = f'gs://cpg-acute-care-test/talos_benchmarking/{input_dir}'

        output_path = f'{output_prefix}/{output_name}/{each_group}'

        # path to the input MT - doubled numbering
        mt_path = f'{input_dir}/{each_group}/{each_group}.mt'

        if not to_path(mt_path).exists():
            print(f'Skipping {each_group}, no MT available at {mt_path}')
            continue

        reports = f'{output_path}/{each_group}_report.tar.gz'
        if to_path(reports).exists():
            print(f'Skipping {each_group}, report already exists at {reports}')
            continue

        new_job = batch_instance.new_bash_job(f'Run Talos for {each_group} sample {run_type} VCF')
        new_job.image(image)
        new_job.cpu(16).memory('32GiB').storage('250GiB')

        new_job.command('set -x')
        new_job.command('mkdir $BATCH_TMPDIR/output')
        new_job.command('mkdir $BATCH_TMPDIR/input')
        new_job.command(f'gcloud storage cp -r {mt_path} $BATCH_TMPDIR/input')
        new_job.command('export TALOS_CONFIG={local_conf}')

        new_job.command(f"""
        nextflow -log {new_job.log} -c nextflow/talos.config \\
              run nextflow/talos.nf \\
              -without-docker -with-report {new_job.report} \\
              --cohort {each_group} \\
              --runtime_config {local_conf} \\
              --matrix_table $BATCH_TMPDIR/input/{each_group}.mt \\
              --pedigree {local_ped} \\
              --panelapp {local_panelapp} \\
              --phenopackets {local_pp} \\
              --parsed_mane {local_mane} \\
              --phenio_db {local_phenio} \\
              --gen2phen {local_g2p} \\
              --clinvar {local_clinvar} \\
              --hpo {local_hpo} \\
              --output_dir $BATCH_TMPDIR/output
        """)
        new_job.command(f'gcloud storage cp -r $BATCH_TMPDIR/output {output_path}')

        hail_batch.get_batch().write_output(new_job.log, f'{output_path}/nextflow.log')
        hail_batch.get_batch().write_output(new_job.report, f'{output_path}/report.html')

batch_instance.run(wait=False)
