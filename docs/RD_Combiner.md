# RD Combiner

## Workflow Usage

* Name: `rd_combiner`
* Description: Combines the gVCFs from the individual sequencing groups into a joint-callset. Runs QC and annotation on the resulting callset. This workflow is a drop-in replacement for `seqr_loader`.
* Version: `N/A`
* Status: `Under Review`
* Source: [rd_combiner.py](https://github.com/populationgenomics/production-pipelines/blob/main/cpg_workflows/stages/rd_combiner.py)

### Instructions

1. Run the `align_and_genotype` workflow on any new samples to generate the gVCFs
2. Run the `rd_combiner` workflow with the `--config configs/create_mt_only.toml` argument to generate the combined callset from gVCFs
3. Once complete, run the `rd_combiner` workflow without the `create_mt_only.toml` config to run all other stages of the pipeline

### Process

The `rd_combiner` workflow runs on gVCFs generated by the `Genotype` Stage. `seqr_loader` used to be continuous with the Align/Genotype stages (i.e. the pipeline would detect missing CRAM/gVCFs and create them), but this pipeline is separated from those initial Stages. As a result, if any SequencingGroups are missing gVCFs, the `align_and_genotype` workflow will have to be run to generate them.

The first Stage `CreateVdsFromGvcfsWithHailCombiner` uses the Hail Combiner to generate a VariantDataset (VDS) from the gVCFs. This aggregates the data from each gVCF without explicitly re-calling any variants. Crucially for our future scaling, this stage can either generate a fresh VDS from gVCFs, or it can incrementally build on an existing VDS by adding the new gVCFs to it. The VDS is a sparse representation of the data, which should have a smaller data footprint than a dense (MatrixTable, MT) representation.

The second stage `CreateDenseMtFromVdsWithHail` reads the VDS and generates a few outputs:
* A MatrixTable with the data from the VDS. This is done by 'densifying' the variant representation to a VCF-equivalent format, and using gnomad utils methods to populate the INFO fields, emulating the INFO which would be generated from a GATK joint-call
* A directory of sites-only VCFs, each having a full VCF header
  * These VCFs are stand-alone fragments, each representing a subset, but can be used in isolation (e.g. in VEP)
* A directory of sites-only VCFs, with a separate header file
  * These VCFs are used to rebuild a whole-genome VCF, required for VQSR training. By exporting fragments in parallel (fast), and concatenating the VCFs through a gcloud command (fast, cheap), we make the best use of the compute resources available.
* A manifest file which can be used to locate all individual sites-only VCFs

This represents the stopping point for the first part of the workflow. The VCF fragments created here are used in scatter-gather operations to parallelise the VQSR QC and variant annotation with VEP. Due to Hail's scheduling mechanics, it needs to know exactly how many partitions there are downstream of this Stage so it can schedule the jobs correctly. We're defaulting to Hail's in-built intervals, which could change in the future, and we have the option to override using a different set of intervals.

There are ways to work around this, but none that are easily maintainable, so I'm leaning on the assumption that this is the best way to do it, at the expense of having to set off two separate workflows.

---

The next Stages in the workflow, `ConcatenateVcfFragmentsWithGcloud` through to `RunTrainedIndelVqsrOnCombinedVcf` all implement the steps of the [make_vqsr_jobs](https://github.com/populationgenomics/production-pipelines/blob/main/cpg_workflows/jobs/vqsr.py#L82-L362) process, but instead of a single run-on task, they're separated into Stages, each Stage representing a single step in the VQSR process. The aim here is to make the code easier to read, and easier to maintain, as the previous process had to be rewritten to use the new splitting strategy and was challenging to unravel..

The next step `AnnotateFragmentedVcfWithVep` is the equivalent of the current [Vep](https://github.com/populationgenomics/production-pipelines/blob/2308ff57cd61709db4d2ec5e52e11cbb98d901ae/cpg_workflows/jobs/vep.py) Stage/jobs, but removes all logic relating to the interval generation and subsetting of the single VCF, and drops all the logic which allows for multiple VEP versions, and multiple output formats.

## Rationale

This new pipeline is designed to replace the current `seqr_loader` workflow which runs Joint-Calling to combine the gVCFs from individual sequencing groups. Joint-Calling is traditionally thought of as a high-quality way of detecting variants across multiple samples, and has a number of advantages over single-sample calling:

- Helps to obtain genotypes for all samples at each site, unlike single-sample calling where WT loci could be missing
- Uses data from multiple samples to help improve the accuracy of genotype calls, e.g. in low coverage regions
- Allows better confidence in detection of de novo variants when used across a trio

With low coverage sequences, it was often essential to jointly analyse samples, to compensate for the low volume of usable data. This doesn't necessarily apply to the high quality datasets we currently have (e.g. 30x+ whole-genome CRAMs), and this creates a different situation:

- In a typical high-depth dataset, the degree of confidence we used to get from joint calling can usually be satisfied by a single sample's data
- For some variant callers, quality is additive across samples. This means that when enough samples contain the same false variant, the caller accumulates enough evidence to call it with confidence

As our datasets continue to scale up, we have an additional problem; Joint Calling needs to be run in full for each callset. To add a single new sample to the callset, we need to reprocess all samples. This becomes prohibitive for large cohorts, and is a major bottleneck for our pipelines.

This workflow represents an attempt to move away from our joint-calling approach, and instead use a computationally simpler method - gVCF combining. This is a simpler and more efficient way of combining the gVCFs from the individual sequencing groups, and in theory should allow us to iterate on callsets much faster and at lower cost.

The initial stages of the pipeline are unaffected (e.g. Genotype) - to begin this RD Combiner workflow we require that each component sequencing group to be included already has a gVCF. The use of this gVCF instead of a variant-only VCF should mitigate some of those joint-calling-specific benefits (e.g. lack of confidently called wild-type sites per-sample).

As the seqr_loader pipeline used to be continuous with the alignment and genotyping pipeline, I've proposed a new workflow `align_and_genotype`, which would be run on new samples to generate the gVCFs, followed later by the RD Combiner workflow to combine the gVCFs into a joint-callset.

## Comparison with the seqr_loader pipeline

`seqr_loader`:
- Create a number of genomic intervals, roughly representing equal sized genomic regions. Numbers depend on cohort size and exome/genome.
- Run GenomicsDBImport and JointGenotyping jobs, one per interval, each creating a VCF (using every gVCF for each interval)
- Combine all VCFs into a single VCF
- Generate a sites-only version of this VCF
- Train VQSR models on the genome-wide sites-only VCF
- Run VQSR once per interval, by passing the whole-genome sites-only VCF and a single interval of interest
- Combine VQSR results into a single VCF
- Run VEP on each interval separately
- Combine VEP results into a single Hail Table
- Read the whole-genome VCF (with genotypes) as a MatrixTable
- Annotate the MatrixTable with the Hail Table of VEP results, and a Hail Table of VQSR results
- Downstream processing for Hail

`rd_combiner`:
- Create a VDS from the gVCFs (defaulting to Hail's preferred intervals for exome or genome)
  - Optionally create a VDS from the union of a previous VDS and new gVCFs
- Densify the VDS to a MatrixTable
- Export the MatrixTable as a collection of sites-only VCFs, one per partition
- Concatenate all the sites-only VCFs into a single VCF
- Train VQSR models on the genome-wide sites-only VCF
- Run VQSR on each separate sites-only VCF by passing only the relevant data
- Combine VQSR results into a single VCF
- Run VEP on each separate sites-only VCF fragment
- Combine VEP results into a single Hail Table
- Load the MT written in step 2, annotate with VEP and VQSR results, and write to a new MT
- Downstream processing for Hail

The main differences are:
- `seqr_loader` needs to create the joint call in full with each run, `rd_combiner` can build incrementally on existing data
- `seqr_loader` generates VCF fragments, reassembles into a single VCF, then subsets that VCF into fragments again later. `rd_combiner` leverages Hail's inbuilt parallelisation to export partial VCFs, and then concatenates them into a single VCF when required.
- `rd_combiner` jobs can be trimmed to a smaller storage requirement, as they use fragments, instead of being passed the whole VCF and only working on a single interval of it.
- `rd_combiner` keeps the joint-call representation in MT format, instead of having to read the VCF as a MT and immediately write the MT representation to disc during downstream processing.

### references...

- [GATK 'Biggest Practices'](https://gatk.broadinstitute.org/hc/en-us/articles/16957867036315-Introducing-GATK-Biggest-Practices-for-Joint-Calling-Supersized-Cohorts)
